<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: goodbrews | davidcel.is]]></title>
  <link href="http://davidcelis.github.io/blog/categories/goodbrews/atom.xml" rel="self"/>
  <link href="http://davidcelis.github.io/"/>
  <updated>2013-04-26T18:34:17-07:00</updated>
  <id>http://davidcelis.github.io/</id>
  <author>
    <name><![CDATA[David Celis]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[From 1.5 GB to 50 MB: The Story of my Redis Database]]></title>
    <link href="http://davidcelis.github.io/blog/2013/03/20/the-story-of-my-redis-database/"/>
    <updated>2013-03-20T11:42:00-07:00</updated>
    <id>http://davidcelis.github.io/blog/2013/03/20/the-story-of-my-redis-database</id>
    <content type="html"><![CDATA[<p>It's been a while since I updated anybody on the current state of goodbre.ws. To make a long story short, I am in the midst of rewriting the site entirely. There are (or were) mainly two large problems for me. One big, niggling problem is that managing the database of beers on my own is impossible. My solution to this is to delegate that out to <a href="http://www.brewerydb.com/">BreweryDB</a>. They have so much more information on their beers than I do that it actually warrants a large rewrite of goodbre.ws. People have consistently asked for a more browsing-oriented experience as opposed to the current search-oriented experience. I'm going to deliver on that. The other big problem was how much memory my Redis instance was taking. Well, I have a small story about that. Yesterday, I reduced that memory usage from 1.5 GB to just 50 MB.</p>

<!--more-->


<p>Last year, with the press on goodbre.ws came a small horde of new users. I found myself with a userbase of about 7000 people. Quite a change from humble beginnings of only a couple hundred friends, classmates and colleagues. However, with all of these new people came a few problems. First, my background jobs to refresh recommendations slowed waaay down. I eventually discovered an I/O bottleneck in the background worker that was hitting both Postgres and Redis more than it reasonably should have been. However, as more and more people were getting their recommendations, I saw my server's RAM usage
quickly get worse and worse. It wasn't long before the amount of RAM that Redis was trying to use had exceeded the amount of RAM on my server (1 GB). I was forced to take goobre.ws down, and here we are.</p>

<p>I started doing a lot of thinking about my Redis usage. What could possibly be causing it to use that much memory? I considered the length of my keys. Typical redis keys looked something like <code>recommendable:users:1234:liked_beers</code>. Okay. Multiply that by five for each user (for dislikes, bookmarks, hidden beers, etc.) and there's a lot of repetition in the key names. They're also quite long. Maybe Redis was eating memory by storing tens of thousands of really long key names in RAM? I decided to try shortening them to a more reasonable format: <code>u:1234:lb</code> for example.</p>

<p>With lots of hope, I renamed my keys and restarted Redis. Hopes dashed: that reduced memory usage by a paltry 0.01 GB. That's 10 MB which, for RAM, may be worth exploring again in the future. However, it obviously wasn't my main problem.</p>

<p>Optimization is a rabbithole I've not had to go down very often. I am hardly an expert. I let my own self-consiousness and self-doubt  get in the way of doing real testing. I immediately jumped to conclusions that, perhaps, Redis was not the tool I wanted to be using. Maybe I should revert to storing ratings in PostgreSQL and accept what would certainly be a large performance hit during recommendation generation.</p>

<p>I toyed with the idea of finding some other data store. I couldn't find a key-value store that, like Redis, had sets and sorted sets but, unlike redis, was not in-memory. I also didn't want to give up the in-memory bit. It's just so fast. The SET and ZSET data structures were also far too perfect for my usage. But what could I do? Redis obviously was becoming too expensive for me. I would have to find something else.</p>

<p>I thought about moving my ratings into a Neo4j graph database. It could make for an interesting way of generating recommendations: it could be a simple graph traversal out from a user to connected (similar) users to find beers that those users like frequently. That would probably even be faster. However, the recommendations themselves would not be as good.</p>

<p>I also thought about simply moving the ratings back into Postgres and initializing some sort of Ruby Set mapping when the Rails app booted up, but that would probably take just as much memory if not more. I'd only be moving RAM usage from Redis to Rails.</p>

<p>Finally, yesterday, I did what I should have done in the first place. I downloaded a <a href="https://github.com/sripathikrishnan/redis-rdb-tools">memory profiling tool</a> built for Redis that would give me key-by-key memory usage stats. What I discovered was surprising, because it outlined a problem I remember thinking about a long time ago. So long ago, in fact, that I thought I had already addressed it.</p>

<p>My issue was how much data I was retaining in each sorted set (ZSET). Each user gets two ZSETs. One is used to store user similarities, and pairs other users' IDs with a calculated similarity value as the rank. The other ZSET stores recommendations, pairing beer IDs with the probability of them liking that beer. In each ZSET, I was keeping those values for every other user and for every other beer. Multiply that by what became a database of 7000 users and 60000 beers and, well, you can guess. Let's just say that a lot of these sets were over 1 MB each.</p>

<p>I thought I was already truncating the ZSETs filled with similarity values by using a k-Nearest-Neighbor setting that I had introduced to Recommendable. That setting uses some specified number of similar users when generating recommendations as opposed to every user. Enabling that setting reduced the size of each similarity set from around 7000 values to 200 (100 similar users and 100 dissimilar users).</p>

<p>Additionally, I implemented a setting to specify how many recommendations should be kept at any one time for each user. I only ever show 10 recommendations, so maintaining those probabilities for every single beer was ridiculous. I reduced that to 100 as well so people can immediately get more recommendations if they rate their current ones.</p>

<p>After truncating all of the sets to their specified lengths, I watched in awe as the memory Redis had been consuming dropped from 1.5 GB to 50 MB. I don't think I'll be having memory usage issues with Redis for a long time.</p>

<p>If you're a <a href="https://github.com/davidcelis/recommendable">Recommendable</a> user, I highly suggest you make use of the <code>nearest_neighbors</code>, <code>furthest_neighbors</code>, and <code>recommendations_to_store</code> settings.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The State of Recommendations in goodbre.ws]]></title>
    <link href="http://davidcelis.github.io/blog/2012/10/03/the-state-of-recommendations-in-goodbrews/"/>
    <updated>2012-10-03T11:27:00-07:00</updated>
    <id>http://davidcelis.github.io/blog/2012/10/03/the-state-of-recommendations-in-goodbrews</id>
    <content type="html"><![CDATA[<p><em>NOTE: This post has been updated. Please click through to read that.</em></p>

<p>Hello, friends and new faces. I want to take a moment to address a question that many of you have had on your mind since you came to <a href="https://goodbre.ws/">goodbre.ws</a>.</p>

<p><blockquote><p>Where are my recommendations?</p><footer><strong>Pretty Much Everybody</strong> <cite></cite></footer></blockquote></p>

<!--more-->


<p>There is (obviously) a problem with how long it is taking for your recommendations to be delivered, and I want to respond to that. I never expected goodbre.ws to be gaining popularity at its current speed. It's all beyond what I had hoped for and is very exciting. You likely found goodbre.ws on <a href="http://lifehacker.com/5947790/goodbrews-tracks-the-beer-you-like-suggests-brews-youd-love">Lifehacker</a> or <a href="http://www.huffingtonpost.com/2012/10/01/goodbrews-beer-recommendations-exploration-website_n_1930567.html?utm_hp_ref=technology">The Huffington Post</a>. I was surprised to discover goodbre.ws was suddenly getting press, and the spikes of traffic have made for a stressful (albeit exciting) few days.</p>

<p>Mainly, however, the heavy increase of traffic has shown me that my current way of serving recommendations isn't particularly scalable. As people join the site, recommendations become exponentially slower. But don't fret! I'm currently working on what will end up being a complete overhaul of <a href="https://github.com/davidcelis/recommendable">Recommendable</a>, the library that I wrote to power goodbre.ws. I'm hoping to have a solution out the door in the next week or two, and I think that it will alleviate this problem.</p>

<p>Until then, some newer users may not see any recommendations at all. I apologize for this. But I also appreciate patience during this period as I figure out what to do with goodbre.ws. Please keep in mind that I'm just one guy doing this on my free time and trying to provide what I think is a really simple and really cool service. Meanwhile, I think that goodbre.ws is still a great way to keep track of the beers you like and don't like. I've been getting great feedback and suggestions from so many people, so I hope that you'll continue to use the site during the next week or two with the understanding that recommendations <em>are</em> coming soon.</p>

<p>Thank you for being patient.</p>

<p><em>UPDATE (14:52 PST, 16 October 2012): Several days ago, I updated <a href="https://github.com/davidcelis/recommendable">recommendable</a> to be much speedier with Recommendations. If you're still not seeing recommendations, please rate one more beer. This will place you in a (now very small) queue, out of which 25 jobs can be processed in parallel. Once your turn comes, it takes about 10 minutes on average to get recommendations. Once you get them, you'll always have them. Any further ratings just improve accuracy. So just be patient for that initial process.</em></p>
]]></content>
  </entry>
  
</feed>
